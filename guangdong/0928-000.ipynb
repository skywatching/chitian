{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanggw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.preprocessing.image\n",
    "import keras.backend as K\n",
    "#from keras.applications.Detect import ResNet50, preprocess_input\n",
    "#from keras.applications.xception import Xception, preprocess_input\n",
    "#from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras import optimizers \n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 6\n",
    "EPOCH_TOTAL = 100000\n",
    "FILE_TAG= \"gd\"\n",
    "\n",
    "IMG_HEIGHT = 1920\n",
    "IMG_WIDTH = 2560\n",
    "\n",
    "INPUT_HEIGHT = IMG_HEIGHT // 2\n",
    "INPUT_WIDTH = IMG_WIDTH // 2\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_round1_train1 = glob.glob(os.path.join(\"./data/guangdong_round1_train1_20180903/\",\"*.jpg\"))\n",
    "train_round1_train2_norm= glob.glob(os.path.join(\"./data/guangdong_round1_train2_20180916/\",\"*/*.jpg\"))\n",
    "train_round1_train2_defect = glob.glob(os.path.join(\"./data/guangdong_round1_train2_20180916/\",\"*/*/*.jpg\"))\n",
    "train_round1_train2_other = glob.glob(os.path.join(\"./data/guangdong_round1_train2_20180916/\",\"*/*/*/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:250 1018 978 140\n"
     ]
    }
   ],
   "source": [
    "print(\"len:{} {} {} {}\".format(len(train_round1_train1),len(train_round1_train2_norm),len(train_round1_train2_defect),len(train_round1_train2_other)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_files = []\n",
    "train_all_files.extend(train_round1_train1)\n",
    "train_all_files.extend(train_round1_train2_norm)\n",
    "train_all_files.extend(train_round1_train2_defect)\n",
    "train_all_files.extend(train_round1_train2_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_name2eng = {\n",
    "    \"正常\": \"norm\",\n",
    "    \"不导电\": \"defect1\",\n",
    "    \"擦花\": \"defect2\",\n",
    "    \"横条压凹\": \"defect3\",\n",
    "    \"桔皮\": \"defect4\",\n",
    "    \"漏底\": \"defect5\",\n",
    "    \"碰伤\": \"defect6\",\n",
    "    \"起坑\": \"defect7\",\n",
    "    \"凸粉\": \"defect8\",\n",
    "    \"涂层开裂\": \"defect9\",\n",
    "    \"脏点\": \"defect10\",\n",
    "    \"其他\": \"defect11\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_defect_class = [\n",
    "    'norm',\n",
    "    'defect1',\n",
    "    'defect2',\n",
    "    'defect3',\n",
    "    'defect4',\n",
    "    'defect5',\n",
    "    'defect6',\n",
    "    'defect7',\n",
    "    'defect8',\n",
    "    'defect9',\n",
    "    'defect10',\n",
    "    'defect11',\n",
    "]\n",
    "\n",
    "g_class_mapping = {defect:classid for classid, defect in enumerate(g_defect_class)}\n",
    "g_class_count = len(g_class_mapping.keys())\n",
    "CLASS_COUNT = g_class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename2label(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    fileclass = basename.split(\"2018\")[0]\n",
    "    label = g_class_mapping[\"defect11\"]\n",
    "    if fileclass in g_name2eng.keys():\n",
    "        label = g_class_mapping[g_name2eng[fileclass]]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testfiles = train_all_files.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914151828对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180913151844对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914090830对照样本.jpg\n",
      "label: 10 fn: defect10 name:./data/guangdong_round1_train2_20180916/瑕疵样本/脏点/脏点20180913105430对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914135913对照样本.jpg\n",
      "label:  2 fn: defect2  name:./data/guangdong_round1_train2_20180916/瑕疵样本/擦花/擦花20180901141803对照样本.jpg\n",
      "label:  5 fn: defect5  name:./data/guangdong_round1_train1_20180903/漏底20180901093218对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180913152516对照样本.jpg\n",
      "label: 11 fn: defect11 name:./data/guangdong_round1_train1_20180903/碰凹20180901104206对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914100117对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180915145532对照样本.jpg\n",
      "label:  6 fn: defect6  name:./data/guangdong_round1_train2_20180916/瑕疵样本/碰伤/碰伤20180905095710对照样本.jpg\n",
      "label: 10 fn: defect10 name:./data/guangdong_round1_train2_20180916/瑕疵样本/脏点/脏点20180907142325对照样本.jpg\n",
      "label:  5 fn: defect5  name:./data/guangdong_round1_train1_20180903/漏底20180901094526对照样本.jpg\n",
      "label:  2 fn: defect2  name:./data/guangdong_round1_train1_20180903/擦花20180901140636对照样本.jpg\n",
      "label:  5 fn: defect5  name:./data/guangdong_round1_train1_20180903/漏底20180901091448对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914105825对照样本.jpg\n",
      "label:  7 fn: defect7  name:./data/guangdong_round1_train2_20180916/瑕疵样本/起坑/起坑20180905102951对照样本.jpg\n",
      "label: 11 fn: defect11 name:./data/guangdong_round1_train2_20180916/瑕疵样本/其他/划伤/划伤20180831152813对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914103634对照样本.jpg\n",
      "label: 11 fn: defect11 name:./data/guangdong_round1_train2_20180916/瑕疵样本/其他/划伤/划伤20180915101713对照样本.jpg\n",
      "label: 10 fn: defect10 name:./data/guangdong_round1_train2_20180916/瑕疵样本/脏点/脏点20180910094739对照样本.jpg\n",
      "label:  0 fn: norm     name:./data/guangdong_round1_train2_20180916/无瑕疵样本/正常20180914135949对照样本.jpg\n",
      "label:  5 fn: defect5  name:./data/guangdong_round1_train1_20180903/漏底20180901092429对照样本.jpg\n",
      "label:  3 fn: defect3  name:./data/guangdong_round1_train2_20180916/瑕疵样本/横条压凹/横条压凹20180903110550对照样本.jpg\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(testfiles)\n",
    "#for i in range(25):\n",
    "#    print(\"label: {:2d} fn: {:8} name:{}\".format(filename2label(testfiles[i]), g_defect_class[filename2label(testfiles[i])], testfiles[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_defect_all2three = np.ones_like(g_defect_class)\n",
    "g_defect_all2three[0] = 0\n",
    "g_defect_all2three[-1] = 2\n",
    "g_defect_all2three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x = x / 255.\n",
    "    x = x - 0.5\n",
    "    x = x * 2.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import logging\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "from keras.utils import Sequence, to_categorical\n",
    "\n",
    "def prehandle_image(img):\n",
    "    imgCLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    imgLAB = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    planesLAB = cv2.split(imgLAB)\n",
    "    planesLAB[0] = imgCLAHE.apply(planesLAB[0])\n",
    "    imgLAB = cv2.merge(planesLAB)\n",
    "    imgLAB = cv2.cvtColor(imgLAB, cv2.COLOR_LAB2RGB)\n",
    "    return imgLAB\n",
    "\n",
    "def load_image(imgfile, augment):\n",
    "    img = cv2.imread(imgfile)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(INPUT_WIDTH, INPUT_HEIGHT))\n",
    "    img = prehandle_image(img)\n",
    "    if augment:\n",
    "        seq = iaa.Sequential([\n",
    "                iaa.Affine(\n",
    "                    shear=(-10,10),\n",
    "                    rotate=(-10,10),\n",
    "                    scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ], random_order=True)\n",
    "        seq_det = seq.to_deterministic()\n",
    "        images_aug = seq_det.augment_images([img])\n",
    "        img = images_aug[0]\n",
    "\n",
    "    return img\n",
    "\n",
    "class FileSequence(Sequence):\n",
    "    def __init__(self, samples, batch_size, augment):\n",
    "        self.samples = samples.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "        self.block_size = int(np.ceil(len(self.samples)/float(self.batch_size)))\n",
    "\n",
    "    def epoch_samples(self):\n",
    "        np.random.shuffle(self.samples)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.epoch_samples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % self.block_size\n",
    "        batch = self.samples[idx*self.batch_size: (idx+1)*self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        batch_labels_3 = []\n",
    "        for f in batch:\n",
    "            img  = load_image(f, self.augment)\n",
    "            classid = filename2label(f)\n",
    "            batch_images.append(img)\n",
    "            batch_labels.append(to_categorical(classid, CLASS_COUNT))\n",
    "            batch_labels_3.append(to_categorical(g_defect_all2three[classid], 3))\n",
    "        batch_images = np.array(batch_images)\n",
    "        if self.augment:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.Sometimes(0.5,\n",
    "                    iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                ),\n",
    "                iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "            ])\n",
    "            batch_images = seq.augment_images(batch_images)\n",
    "        batch_images = preprocess_input(batch_images.astype(np.float32))\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_labels_3 = np.array(batch_labels_3)\n",
    "        return batch_images, [batch_labels_3, batch_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTFUNC = LeakyReLU(0.1)\n",
    "#'relu'\n",
    "\n",
    "def detect_model(classcnt):\n",
    "    model_input = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "\n",
    "    x = model_input\n",
    "    x05 = Conv2D(64, ( 5,  5), strides=(3, 4), activation=ACTFUNC, padding='same', name='block1_conv1')(x)\n",
    "    x07 = Conv2D(64, ( 7,  7), strides=(3, 4), activation=ACTFUNC, padding='same', name='block1_conv2')(x)\n",
    "    x09 = Conv2D(64, ( 9,  9), strides=(3, 4), activation=ACTFUNC, padding='same', name='block1_conv3')(x)\n",
    "    x11 = Conv2D(64, (11, 11), strides=(3, 4), activation=ACTFUNC, padding='same', name='block1_conv4')(x)\n",
    "    x = layers.concatenate([x05, x07, x09, x11])\n",
    "    #res160 = Conv2D(128, (7, 7), strides=(4, 4), activation=ACTFUNC, padding='same', name='res_conv160')(x)\n",
    "\n",
    "    x23 = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block2_conv1')(x)\n",
    "    x25 = Conv2D(64, (5, 5), strides=(2, 2), activation=ACTFUNC, padding='same', name='block2_conv2')(x)\n",
    "    x27 = Conv2D(64, (7, 7), strides=(2, 2), activation=ACTFUNC, padding='same', name='block2_conv3')(x)\n",
    "    x29 = Conv2D(64, (9, 9), strides=(2, 2), activation=ACTFUNC, padding='same', name='block2_conv4')(x)\n",
    "    x = layers.concatenate([x23, x25, x27, x29])\n",
    "\n",
    "    #out320 = Conv2D(64, (5, 5), strides=(4, 4), activation=ACTFUNC, padding='same', name='block4_out320_0')(x)\n",
    "    #out320 = Conv2D(64, (5, 5), strides=(4, 4), activation=ACTFUNC, padding='same', name='block4_out320_1')(x)\n",
    "    #out320 = layers.GlobalAveragePooling2D()(out320)\n",
    "#   out320 = Dense(classcnt, activation='softmax', name='out320')(out320)\n",
    "    #res80 = Conv2D(128, (7, 7), strides=(4, 4), activation=ACTFUNC, padding='same', name='res_conv080')(x)\n",
    "\n",
    " \n",
    "    x33 = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block3_conv1')(x)\n",
    "    x35 = Conv2D(64, (5, 5), strides=(2, 2), activation=ACTFUNC, padding='same', name='block3_conv2')(x)\n",
    "    x37 = Conv2D(64, (7, 7), strides=(2, 2), activation=ACTFUNC, padding='same', name='block3_conv3')(x)\n",
    "    x39 = Conv2D(64, (9, 9), strides=(2, 2), activation=ACTFUNC, padding='same', name='block3_conv4')(x)\n",
    "    #x = layers.concatenate([x33, x35, x37, res160])\n",
    "    x = layers.concatenate([x33, x35, x37, x39])\n",
    "\n",
    "    out160 = Conv2D(64, (5, 5), strides=(4, 4), activation=ACTFUNC, padding='same', name='block4_out160_0')(x)\n",
    "    out160 = Conv2D(64, (5, 5), strides=(4, 4), activation=ACTFUNC, padding='same', name='block4_out160_1')(x)\n",
    "    out160 = layers.GlobalAveragePooling2D()(out160)\n",
    "    #out160 = Dense(classcnt, activation='softmax', name='out160')(out160)\n",
    "    out160 = Dense(3, activation='softmax', name='out160')(out160)\n",
    "\n",
    "    x43 = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block4_conv1')(x)\n",
    "    x45 = Conv2D(64, (5, 5), strides=(2, 2), activation=ACTFUNC, padding='same', name='block4_conv2')(x)\n",
    "    #x = layers.concatenate([x43, x47, res80])\n",
    "    x = layers.concatenate([x43, x45])\n",
    "    #out080 = Conv2D(64, (5, 5), strides=(4, 4), activation=ACTFUNC, padding='same', name='block4_out080')(x)\n",
    "    #out080 = layers.GlobalAveragePooling2D()(out080)\n",
    "#   out080 = Dense(classcnt, activation='softmax', name='out080')(out080)\n",
    "\n",
    "    x53 = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block5_conv1')(x)\n",
    "    x55 = Conv2D(64, (5, 5), strides=(2, 2), activation=ACTFUNC, padding='same', name='block5_conv2')(x)\n",
    "    x = layers.concatenate([x53, x55])\n",
    "\n",
    "    #res10 = Conv2D(512, (7, 7), strides=(4, 4), activation=ACTFUNC, padding='same', name='res_conv010')(x)\n",
    " \n",
    "    x63 = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block6_conv1')(x)\n",
    "    x65 = Conv2D(64, (5, 5), strides=(2, 2), activation=ACTFUNC, padding='same', name='block6_conv2')(x)\n",
    "    x = layers.concatenate([x63, x65])\n",
    "\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block7_conv1')(x)\n",
    "    #x = layers.concatenate([x, res10])\n",
    " \n",
    "    #x = Conv2D(512, (3, 3), strides=(2, 2), activation=ACTFUNC, padding='same', name='block7_conv2')(x)\n",
    "    #x = MaxPooling2D((2, 2), strides=(2, 2), name='block7_pool')(x)\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    " \n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(512, activation=ACTFUNC)(x)\n",
    "    out = Dense(classcnt, activation='softmax', name='out')(x)\n",
    "\n",
    "    model = Model(inputs=model_input, outputs=[out160, out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def FScore1(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=1)\n",
    "\n",
    "def FScore2(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanggw/anaconda3/lib/python3.6/site-packages/keras/activations.py:103: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 960, 1280, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 320, 320, 64) 4864        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 320, 320, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv3 (Conv2D)           (None, 320, 320, 64) 15616       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv4 (Conv2D)           (None, 320, 320, 64) 23296       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 320, 320, 256 0           block1_conv1[0][0]               \n",
      "                                                                 block1_conv2[0][0]               \n",
      "                                                                 block1_conv3[0][0]               \n",
      "                                                                 block1_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 160, 160, 64) 147520      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 160, 160, 64) 409664      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3 (Conv2D)           (None, 160, 160, 64) 802880      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv4 (Conv2D)           (None, 160, 160, 64) 1327168     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 160, 160, 256 0           block2_conv1[0][0]               \n",
      "                                                                 block2_conv2[0][0]               \n",
      "                                                                 block2_conv3[0][0]               \n",
      "                                                                 block2_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 80, 80, 64)   147520      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 80, 80, 64)   409664      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 80, 80, 64)   802880      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 80, 80, 64)   1327168     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 80, 80, 256)  0           block3_conv1[0][0]               \n",
      "                                                                 block3_conv2[0][0]               \n",
      "                                                                 block3_conv3[0][0]               \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 40, 40, 64)   147520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 40, 40, 64)   409664      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 40, 40, 128)  0           block4_conv1[0][0]               \n",
      "                                                                 block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 20, 20, 64)   73792       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 20, 20, 64)   204864      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 20, 20, 128)  0           block5_conv1[0][0]               \n",
      "                                                                 block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv1 (Conv2D)           (None, 10, 10, 64)   73792       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv2 (Conv2D)           (None, 10, 10, 64)   204864      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 10, 10, 128)  0           block6_conv1[0][0]               \n",
      "                                                                 block6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_out160_1 (Conv2D)        (None, 20, 20, 64)   409664      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv1 (Conv2D)           (None, 5, 5, 64)     73792       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           block4_out160_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 64)           0           block7_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "out160 (Dense)                  (None, 12)           780         global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 12)           780         avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,027,224\n",
      "Trainable params: 7,027,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = detect_model(CLASS_COUNT)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = FileSequence(train_all_files, BATCH_SIZE_TRAIN, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfiles = sorted(glob.glob('./output/{}*/*.h5'.format(FILE_TAG)))\n",
    "init_epoch = 0\n",
    "log_path = os.path.join('./output/{}-{:%Y%m%dT%H%M}'.format(FILE_TAG, datetime.datetime.now()))\n",
    "if modelfiles:\n",
    "    modelfile = modelfiles[-1]\n",
    "    log_path = os.path.dirname(modelfile)\n",
    "    model.load_weights(modelfile)\n",
    "    filename = os.path.splitext(os.path.basename(modelfile))[0]\n",
    "    init_epoch = int(filename.split('_')[-2])\n",
    "checkout_file = os.path.join(log_path, \"{}_*epoch*.h5\".format(FILE_TAG))\n",
    "checkout_file = checkout_file.replace(\"*epoch*\", \"{epoch:04d}_{out_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zhanggw/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2880: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#optimizer = keras.optimizers.SGD(lr=0.0125, momentum=0.9, decay=1e-6, nesterov=False)\n",
    "#model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc', precision, recall])\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', precision, recall])\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss={\n",
    "        'out160':'categorical_crossentropy',\n",
    "        'out':'categorical_crossentropy',\n",
    "    },\n",
    "    loss_weights={\n",
    "        'out160': 1,\n",
    "        'out': 1.,\n",
    "    },\n",
    "    metrics=['acc', precision, recall, FScore1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "callbacks.append(TensorBoard(log_dir=log_path, write_images=False))\n",
    "callbacks.append(ModelCheckpoint(checkout_file, monitor='out_acc', save_weights_only=True, save_best_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    initial_epoch = init_epoch,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    epochs = EPOCH_TOTAL,\n",
    "    validation_data = None,#valid_generator,\n",
    "    #validation_steps = len(valid_generator),\n",
    "    verbose = 1,\n",
    "    callbacks = callbacks\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
